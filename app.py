import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
import joblib
import os

# Configuration de base
st.set_page_config(
    page_title="D√©tecteur de Fake News",
    page_icon="üì∞"
)

# Titre
st.title("D√©tecteur de Fake News üì∞")

# Donn√©es d'exemple
FAKE_TEXTS = [
    "BREAKING: Scientists discover unicorns in Antarctica!",
    "Aliens make contact with Earth government",
    "New study proves chocolate cures all diseases",
    "Time travel machine invented in garage",
    "World's first flying car goes on sale next week"
]

REAL_TEXTS = [
    "New study shows benefits of regular exercise",
    "Local school wins regional science competition",
    "City council approves new park development",
    "Weather forecast predicts rain for weekend",
    "New restaurant opens in downtown area"
]

# Fonction pour cr√©er et entra√Æner le mod√®le
def create_model():
    # Cr√©er le vectorizer et le classifieur
    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
    classifier = RandomForestClassifier(n_estimators=100, random_state=42)
    
    # Pr√©parer les donn√©es
    texts = FAKE_TEXTS + REAL_TEXTS
    labels = [1] * len(FAKE_TEXTS) + [0] * len(REAL_TEXTS)
    
    # Entra√Æner le mod√®le
    X = vectorizer.fit_transform(texts)
    classifier.fit(X, labels)
    
    return vectorizer, classifier

# Interface principale
try:
    # Cr√©er ou charger le mod√®le
    vectorizer, classifier = create_model()
    
    # Interface de saisie
    st.header("üìù Analyser un article")
    
    with st.form("news_form"):
        text = st.text_area("Contenu de l'article", height=200)
        submitted = st.form_submit_button("Analyser")
    
    if submitted and text:
        with st.spinner("Analyse en cours..."):
            try:
                # Pr√©parer le texte
                X = vectorizer.transform([text])
                
                # Faire la pr√©diction
                prediction = classifier.predict(X)[0]
                probability = classifier.predict_proba(X)[0]
                
                # Afficher les r√©sultats
                st.header("üìä R√©sultats de l'analyse")
                
                if prediction == 1:
                    st.error("‚ö†Ô∏è Cet article est probablement une FAKE NEWS")
                else:
                    st.success("‚úÖ Cet article semble fiable")
                
                # Afficher la confiance
                confidence = probability[1] if prediction == 1 else probability[0]
                st.metric("Indice de confiance", f"{confidence*100:.1f}%")
                
                # Afficher des conseils
                st.info("üí° Conseils pour √©valuer la fiabilit√© d'un article :")
                st.markdown("""
                - V√©rifiez la source de l'article
                - Recherchez des informations similaires sur d'autres sites fiables
                - M√©fiez-vous des titres sensationnels ou exag√©r√©s
                - V√©rifiez la date de publication
                - Examinez les citations et les sources cit√©es
                """)
                
            except Exception as e:
                st.error(f"Erreur lors de l'analyse : {str(e)}")
    
    # √Ä propos
    st.markdown("---")
    st.header("‚ÑπÔ∏è √Ä propos")
    st.write("Cette application utilise un mod√®le simple de machine learning pour d√©tecter les fake news.")
    st.write("Le mod√®le a √©t√© entra√Æn√© sur un petit ensemble de donn√©es d'exemple.")
    st.write("‚ö†Ô∏è Note : Cette version est une d√©monstration simplifi√©e. Pour une analyse plus pr√©cise, utilisez votre jugement critique et v√©rifiez les sources.")

except Exception as e:
    st.error(f"Une erreur est survenue : {str(e)}")
    st.info("Si le probl√®me persiste, essayez de red√©marrer l'application.")
